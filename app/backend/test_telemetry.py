#!/usr/bin/env python3
"""
Test script to verify Azure Monitor telemetry configuration.
Run this to check if your telemetry setup is working correctly.
"""
import os
import sys
import time
import asyncio
from pathlib import Path

# Add the backend directory to Python path
sys.path.insert(0, str(Path(__file__).parent))

def test_environment_variables():
    """Test if required environment variables are present"""
    print("üîç Checking environment variables...")
    
    required_vars = [
        "APPLICATIONINSIGHTS_CONNECTION_STRING",
        "AZURE_RESOURCE_GROUP"
    ]
    
    optional_vars = [
        "APPINSIGHTS_INSTRUMENTATIONKEY",
        "AZURE_AI_FOUNDRY_HUB_NAME",
        "AZURE_AI_FOUNDRY_PROJECT_NAME",
        "RUNNING_IN_PRODUCTION"
    ]
    
    results = {"found": [], "missing": [], "optional": []}
    
    for var in required_vars:
        value = os.environ.get(var)
        if value:
            # Mask sensitive values
            if "CONNECTION_STRING" in var:
                masked_value = f"{value[:20]}...{value[-10:]}" if len(value) > 30 else value
                results["found"].append(f"{var}={masked_value}")
            else:
                results["found"].append(f"{var}={value}")
        else:
            results["missing"].append(var)
    
    for var in optional_vars:
        value = os.environ.get(var)
        if value:
            results["optional"].append(f"{var}={value}")
    
    print(f"‚úÖ Found required variables: {len(results['found'])}")
    for var in results["found"]:
        print(f"   ‚úì {var}")
    
    if results["missing"]:
        print(f"‚ùå Missing required variables: {len(results['missing'])}")
        for var in results["missing"]:
            print(f"   ‚úó {var}")
    
    if results["optional"]:
        print(f"‚ÑπÔ∏è  Optional variables found: {len(results['optional'])}")
        for var in results["optional"]:
            print(f"   ‚Ä¢ {var}")
    
    return len(results["missing"]) == 0

def test_azure_monitor_import():
    """Test if Azure Monitor packages are available"""
    print("\nüì¶ Testing Azure Monitor package imports...")
    
    try:
        from azure.monitor.opentelemetry import configure_azure_monitor
        print("‚úÖ Azure Monitor OpenTelemetry package available")
        return True
    except ImportError as e:
        print(f"‚ùå Azure Monitor OpenTelemetry not available: {e}")
        print("üí° Install with: pip install azure-monitor-opentelemetry")
        return False

def test_telemetry_setup():
    """Test the telemetry setup function"""
    print("\nüîß Testing telemetry setup...")
    
    try:
        from telemetry import setup_azure_monitor, verify_telemetry_setup
        
        # Run setup
        setup_result = setup_azure_monitor()
        print(f"Setup result: {setup_result}")
        
        # Run diagnostics
        diagnostics = verify_telemetry_setup()
        
        print(f"‚úÖ Telemetry diagnostics completed")
        print(f"   Connection string found: {diagnostics.get('connection_string_found', False)}")
        print(f"   Azure Monitor available: {diagnostics.get('azure_monitor_available', False)}")
        print(f"   Test trace created: {diagnostics.get('test_trace_created', False)}")
        
        if diagnostics.get("errors"):
            print(f"‚ö†Ô∏è  Errors found: {len(diagnostics['errors'])}")
            for error in diagnostics["errors"]:
                print(f"   ‚Ä¢ {error}")
        
        return setup_result
        
    except Exception as e:
        print(f"‚ùå Telemetry setup test failed: {e}")
        return False

def test_trace_creation():
    """Test creating traces"""
    print("\nüéØ Testing trace creation...")
    
    try:
        from telemetry import trace_tool_call, trace_model_call, get_tracer
        
        # Test tool call tracing
        print("Creating test tool call trace...")
        with trace_tool_call("test_tool", {"param1": "value1"}, 0.123, {"result": "success"}) as span:
            print(f"   Tool call span created: {span}")
        
        # Test model call tracing
        print("Creating test model call trace...")
        with trace_model_call("gpt-4o", "completion", 150, 0.456, 0.02, "test prompt", "test response") as span:
            print(f"   Model call span created: {span}")
        
        print("‚úÖ Trace creation test completed")
        return True
        
    except Exception as e:
        print(f"‚ùå Trace creation test failed: {e}")
        return False

async def test_api_endpoints():
    """Test telemetry API endpoints"""
    print("\nüåê Testing API endpoints...")
    
    try:
        import aiohttp
        
        # Test if we can reach the diagnostics endpoint
        # This would only work if the server is running
        print("Note: API endpoint test requires the server to be running")
        print("You can test manually by visiting:")
        print("   GET /api/telemetry/diagnostics")
        print("   GET /api/telemetry")
        
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è  API endpoint test skipped: {e}")
        return True

def main():
    """Main test function"""
    print("üöÄ Azure Monitor Telemetry Configuration Test")
    print("=" * 50)
    
    # Load environment from .env if not in production
    if not os.environ.get("RUNNING_IN_PRODUCTION"):
        try:
            from dotenv import load_dotenv
            load_dotenv()
            print("üìÅ Loaded environment from .env file")
        except ImportError:
            print("‚ö†Ô∏è  python-dotenv not available, skipping .env loading")
    
    tests = [
        ("Environment Variables", test_environment_variables),
        ("Azure Monitor Import", test_azure_monitor_import),
        ("Telemetry Setup", test_telemetry_setup),
        ("Trace Creation", test_trace_creation),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"‚ùå {test_name} test failed with exception: {e}")
            results.append((test_name, False))
    
    # Run async test
    try:
        print("\nRunning async tests...")
        asyncio.run(test_api_endpoints())
        results.append(("API Endpoints", True))
    except Exception as e:
        print(f"‚ùå API endpoints test failed: {e}")
        results.append(("API Endpoints", False))
    
    # Summary
    print("\nüìä Test Results Summary")
    print("=" * 30)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status} {test_name}")
    
    print(f"\nüéØ Overall: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ All tests passed! Your telemetry configuration looks good.")
        return 0
    else:
        print("‚ö†Ô∏è  Some tests failed. Check the output above for details.")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)